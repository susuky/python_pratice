{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:26:48.493477Z",
     "start_time": "2021-09-17T18:26:45.998182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "#import lightgbm as lgbm\n",
    "import optuna.integration.lightgbm as lgbm\n",
    "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
    "\n",
    "pd.set_option('max_columns', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:32:14.537419Z",
     "start_time": "2021-09-17T18:32:14.533514Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmspe(preds, ys): return (((preds - ys) / ys) ** 2).mean() ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:27:06.423774Z",
     "start_time": "2021-09-17T18:27:02.123761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>row_id</th>\n",
       "      <th>wap1_mean</th>\n",
       "      <th>log_return1_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>wap1_mean_450</th>\n",
       "      <th>log_return1_realized_volatility_450</th>\n",
       "      <th>log_return2_realized_volatility_450</th>\n",
       "      <th>wap_balance_mean_450</th>\n",
       "      <th>price_spread_mean_450</th>\n",
       "      <th>bid_spread_mean_450</th>\n",
       "      <th>ask_spread_mean_450</th>\n",
       "      <th>total_volume_mean_450</th>\n",
       "      <th>volume_imbalance_mean_450</th>\n",
       "      <th>wap1_mean_300</th>\n",
       "      <th>log_return1_realized_volatility_300</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>wap1_mean_150</th>\n",
       "      <th>log_return1_realized_volatility_150</th>\n",
       "      <th>log_return2_realized_volatility_150</th>\n",
       "      <th>wap_balance_mean_150</th>\n",
       "      <th>price_spread_mean_150</th>\n",
       "      <th>bid_spread_mean_150</th>\n",
       "      <th>ask_spread_mean_150</th>\n",
       "      <th>total_volume_mean_150</th>\n",
       "      <th>volume_imbalance_mean_150</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_450</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_450</th>\n",
       "      <th>trade_size_sum_450</th>\n",
       "      <th>trade_order_count_mean_450</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility_150</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_150</th>\n",
       "      <th>trade_size_sum_150</th>\n",
       "      <th>trade_order_count_mean_150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0-5</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>1.003482</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>263.941176</td>\n",
       "      <td>141.470588</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>1.003832</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>327.431034</td>\n",
       "      <td>123.586207</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2069.0</td>\n",
       "      <td>2.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0-11</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>1.000518</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>447.981481</td>\n",
       "      <td>97.685185</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>1.000301</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>419.277457</td>\n",
       "      <td>151.566474</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>2.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>459.113636</td>\n",
       "      <td>156.113636</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>428.537815</td>\n",
       "      <td>132.084034</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>424.234568</td>\n",
       "      <td>151.765432</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>3.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>391.944444</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>371.266667</td>\n",
       "      <td>131.474074</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>32751</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>406.045161</td>\n",
       "      <td>161.638710</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>347.333333</td>\n",
       "      <td>119.466667</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>379.443662</td>\n",
       "      <td>150.471831</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>412.590308</td>\n",
       "      <td>152.731278</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>2.783784</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>12.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>18.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>2.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>32753</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>126-32753</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>243.322870</td>\n",
       "      <td>150.578475</td>\n",
       "      <td>1.004174</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>232.462963</td>\n",
       "      <td>121.203704</td>\n",
       "      <td>1.003528</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>242.561905</td>\n",
       "      <td>153.819048</td>\n",
       "      <td>1.002893</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>225.834320</td>\n",
       "      <td>139.384615</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>3.418605</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>13.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>3.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>32758</td>\n",
       "      <td>0.004070</td>\n",
       "      <td>126-32758</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>348.093750</td>\n",
       "      <td>254.406250</td>\n",
       "      <td>1.001527</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>344.459770</td>\n",
       "      <td>285.218391</td>\n",
       "      <td>1.001282</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>343.592814</td>\n",
       "      <td>249.401198</td>\n",
       "      <td>1.001142</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>339.199005</td>\n",
       "      <td>246.313433</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>6.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>2.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>32763</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>126-32763</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>426.416040</td>\n",
       "      <td>145.654135</td>\n",
       "      <td>1.001663</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>470.470000</td>\n",
       "      <td>160.490000</td>\n",
       "      <td>1.001807</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>471.183246</td>\n",
       "      <td>159.832461</td>\n",
       "      <td>1.001855</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>453.528814</td>\n",
       "      <td>160.132203</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9389.0</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>2.813953</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>2.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>32767</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>126-32767</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>531.313364</td>\n",
       "      <td>177.442396</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>626.537037</td>\n",
       "      <td>289.574074</td>\n",
       "      <td>1.000249</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>502.406250</td>\n",
       "      <td>212.052083</td>\n",
       "      <td>1.000203</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>512.353741</td>\n",
       "      <td>185.986395</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>3.588235</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>3.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  time_id    target     row_id  wap1_mean  \\\n",
       "0              0        5  0.004136        0-5   1.003725   \n",
       "1              0       11  0.001445       0-11   1.000239   \n",
       "2              0       16  0.002168       0-16   0.999542   \n",
       "3              0       31  0.002195       0-31   0.998832   \n",
       "4              0       62  0.001747       0-62   0.999619   \n",
       "...          ...      ...       ...        ...        ...   \n",
       "428927       126    32751  0.003461  126-32751   0.999582   \n",
       "428928       126    32753  0.003113  126-32753   1.002476   \n",
       "428929       126    32758  0.004070  126-32758   1.001082   \n",
       "428930       126    32763  0.003357  126-32763   1.001809   \n",
       "428931       126    32767  0.002090  126-32767   1.000272   \n",
       "\n",
       "        log_return1_realized_volatility  log_return2_realized_volatility  \\\n",
       "0                              0.004499                         0.006999   \n",
       "1                              0.001204                         0.002476   \n",
       "2                              0.002369                         0.004801   \n",
       "3                              0.002574                         0.003637   \n",
       "4                              0.001894                         0.003257   \n",
       "...                                 ...                              ...   \n",
       "428927                         0.003691                         0.005876   \n",
       "428928                         0.004104                         0.004991   \n",
       "428929                         0.003117                         0.006020   \n",
       "428930                         0.003661                         0.005362   \n",
       "428931                         0.002092                         0.003037   \n",
       "\n",
       "        wap_balance_mean  price_spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0               0.000388           0.000852         0.000176        -0.000151   \n",
       "1               0.000212           0.000394         0.000142        -0.000135   \n",
       "2               0.000331           0.000725         0.000197        -0.000198   \n",
       "3               0.000380           0.000860         0.000190        -0.000108   \n",
       "4               0.000254           0.000397         0.000191        -0.000109   \n",
       "...                  ...                ...              ...              ...   \n",
       "428927          0.000361           0.000878         0.000091        -0.000202   \n",
       "428928          0.000295           0.000706         0.000126        -0.000142   \n",
       "428929          0.000394           0.000739         0.000189        -0.000192   \n",
       "428930          0.000231           0.000530         0.000143        -0.000134   \n",
       "428931          0.000216           0.000432         0.000109        -0.000159   \n",
       "\n",
       "        total_volume_mean  volume_imbalance_mean  wap1_mean_450  \\\n",
       "0              323.496689             134.894040       1.003482   \n",
       "1              411.450000             142.050000       1.000518   \n",
       "2              416.351064             141.414894       0.998237   \n",
       "3              435.266667             146.216667       0.998079   \n",
       "4              343.221591             123.846591       0.999518   \n",
       "...                   ...                    ...            ...   \n",
       "428927         406.045161             161.638710       0.999301   \n",
       "428928         243.322870             150.578475       1.004174   \n",
       "428929         348.093750             254.406250       1.001527   \n",
       "428930         426.416040             145.654135       1.001663   \n",
       "428931         531.313364             177.442396       0.999967   \n",
       "\n",
       "        log_return1_realized_volatility_450  \\\n",
       "0                                  0.001721   \n",
       "1                                  0.000918   \n",
       "2                                  0.001158   \n",
       "3                                  0.000993   \n",
       "4                                  0.001378   \n",
       "...                                     ...   \n",
       "428927                             0.001701   \n",
       "428928                             0.002613   \n",
       "428929                             0.001551   \n",
       "428930                             0.001704   \n",
       "428931                             0.000952   \n",
       "\n",
       "        log_return2_realized_volatility_450  wap_balance_mean_450  \\\n",
       "0                                  0.004114              0.000366   \n",
       "1                                  0.001883              0.000269   \n",
       "2                                  0.002972              0.000365   \n",
       "3                                  0.001424              0.000358   \n",
       "4                                  0.000966              0.000364   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.002461              0.000338   \n",
       "428928                             0.002698              0.000278   \n",
       "428929                             0.003079              0.000455   \n",
       "428930                             0.001979              0.000190   \n",
       "428931                             0.001595              0.000217   \n",
       "\n",
       "        price_spread_mean_450  bid_spread_mean_450  ask_spread_mean_450  \\\n",
       "0                    0.000783             0.000262            -0.000166   \n",
       "1                    0.000348             0.000233            -0.000143   \n",
       "2                    0.000605             0.000186            -0.000208   \n",
       "3                    0.001058             0.000116            -0.000049   \n",
       "4                    0.000519             0.000196            -0.000136   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000840             0.000098            -0.000129   \n",
       "428928               0.000708             0.000101            -0.000179   \n",
       "428929               0.000657             0.000326            -0.000221   \n",
       "428930               0.000464             0.000138            -0.000130   \n",
       "428931               0.000461             0.000090            -0.000134   \n",
       "\n",
       "        total_volume_mean_450  volume_imbalance_mean_450  wap1_mean_300  \\\n",
       "0                  263.941176                 141.470588       1.003753   \n",
       "1                  447.981481                  97.685185       1.000397   \n",
       "2                  459.113636                 156.113636       0.998685   \n",
       "3                  540.000000                 146.000000       0.998436   \n",
       "4                  391.944444                 117.000000       0.999488   \n",
       "...                       ...                        ...            ...   \n",
       "428927             347.333333                 119.466667       0.999375   \n",
       "428928             232.462963                 121.203704       1.003528   \n",
       "428929             344.459770                 285.218391       1.001282   \n",
       "428930             470.470000                 160.490000       1.001807   \n",
       "428931             626.537037                 289.574074       1.000249   \n",
       "\n",
       "        log_return1_realized_volatility_300  \\\n",
       "0                                  0.002953   \n",
       "1                                  0.000981   \n",
       "2                                  0.001295   \n",
       "3                                  0.001776   \n",
       "4                                  0.001520   \n",
       "...                                     ...   \n",
       "428927                             0.002899   \n",
       "428928                             0.003454   \n",
       "428929                             0.002792   \n",
       "428930                             0.002379   \n",
       "428931                             0.001414   \n",
       "\n",
       "        log_return2_realized_volatility_300  wap_balance_mean_300  \\\n",
       "0                                  0.004863              0.000372   \n",
       "1                                  0.002009              0.000239   \n",
       "2                                  0.003196              0.000431   \n",
       "3                                  0.002713              0.000331   \n",
       "4                                  0.002188              0.000252   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.003776              0.000297   \n",
       "428928                             0.003402              0.000280   \n",
       "428929                             0.005387              0.000430   \n",
       "428930                             0.003182              0.000199   \n",
       "428931                             0.002457              0.000227   \n",
       "\n",
       "        price_spread_mean_300  bid_spread_mean_300  ask_spread_mean_300  \\\n",
       "0                    0.000822             0.000223            -0.000162   \n",
       "1                    0.000353             0.000164            -0.000123   \n",
       "2                    0.000689             0.000141            -0.000249   \n",
       "3                    0.000833             0.000158            -0.000095   \n",
       "4                    0.000425             0.000191            -0.000120   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000890             0.000091            -0.000162   \n",
       "428928               0.000729             0.000147            -0.000168   \n",
       "428929               0.000704             0.000244            -0.000200   \n",
       "428930               0.000493             0.000150            -0.000118   \n",
       "428931               0.000430             0.000108            -0.000164   \n",
       "\n",
       "        total_volume_mean_300  volume_imbalance_mean_300  wap1_mean_150  \\\n",
       "0                  294.928058                 137.158273       1.003832   \n",
       "1                  484.521739                 135.513043       1.000301   \n",
       "2                  455.235294                 144.147059       0.999126   \n",
       "3                  418.169811                 144.698113       0.998464   \n",
       "4                  407.584270                  99.449438       0.999618   \n",
       "...                       ...                        ...            ...   \n",
       "428927             379.443662                 150.471831       0.999375   \n",
       "428928             242.561905                 153.819048       1.002893   \n",
       "428929             343.592814                 249.401198       1.001142   \n",
       "428930             471.183246                 159.832461       1.001855   \n",
       "428931             502.406250                 212.052083       1.000203   \n",
       "\n",
       "        log_return1_realized_volatility_150  \\\n",
       "0                                  0.003796   \n",
       "1                                  0.001058   \n",
       "2                                  0.002138   \n",
       "3                                  0.002196   \n",
       "4                                  0.001609   \n",
       "...                                     ...   \n",
       "428927                             0.003438   \n",
       "428928                             0.003972   \n",
       "428929                             0.002955   \n",
       "428930                             0.003042   \n",
       "428931                             0.001656   \n",
       "\n",
       "        log_return2_realized_volatility_150  wap_balance_mean_150  \\\n",
       "0                                  0.006087              0.000397   \n",
       "1                                  0.002262              0.000205   \n",
       "2                                  0.004019              0.000373   \n",
       "3                                  0.003273              0.000362   \n",
       "4                                  0.002927              0.000242   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.005201              0.000372   \n",
       "428928                             0.004569              0.000307   \n",
       "428929                             0.005654              0.000393   \n",
       "428930                             0.004462              0.000210   \n",
       "428931                             0.002595              0.000190   \n",
       "\n",
       "        price_spread_mean_150  bid_spread_mean_150  ask_spread_mean_150  \\\n",
       "0                    0.000858             0.000188            -0.000147   \n",
       "1                    0.000353             0.000141            -0.000127   \n",
       "2                    0.000679             0.000161            -0.000241   \n",
       "3                    0.000920             0.000170            -0.000108   \n",
       "4                    0.000395             0.000187            -0.000117   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000904             0.000090            -0.000181   \n",
       "428928               0.000726             0.000131            -0.000148   \n",
       "428929               0.000713             0.000211            -0.000199   \n",
       "428930               0.000513             0.000149            -0.000130   \n",
       "428931               0.000412             0.000098            -0.000154   \n",
       "\n",
       "        total_volume_mean_150  volume_imbalance_mean_150  \\\n",
       "0                  327.431034                 123.586207   \n",
       "1                  419.277457                 151.566474   \n",
       "2                  428.537815                 132.084034   \n",
       "3                  424.234568                 151.765432   \n",
       "4                  371.266667                 131.474074   \n",
       "...                       ...                        ...   \n",
       "428927             412.590308                 152.731278   \n",
       "428928             225.834320                 139.384615   \n",
       "428929             339.199005                 246.313433   \n",
       "428930             453.528814                 160.132203   \n",
       "428931             512.353741                 185.986395   \n",
       "\n",
       "        trade_log_return_realized_volatility  \\\n",
       "0                                   0.002006   \n",
       "1                                   0.000901   \n",
       "2                                   0.001961   \n",
       "3                                   0.001561   \n",
       "4                                   0.000871   \n",
       "...                                      ...   \n",
       "428927                              0.002171   \n",
       "428928                              0.002180   \n",
       "428929                              0.001921   \n",
       "428930                              0.002051   \n",
       "428931                              0.001041   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40.0          3179.0   \n",
       "1                                       30.0          1289.0   \n",
       "2                                       25.0          2161.0   \n",
       "3                                       15.0          1962.0   \n",
       "4                                       22.0          1791.0   \n",
       "...                                      ...             ...   \n",
       "428927                                  37.0          2570.0   \n",
       "428928                                  43.0          2323.0   \n",
       "428929                                  35.0          3740.0   \n",
       "428930                                  80.0          9389.0   \n",
       "428931                                  36.0          5325.0   \n",
       "\n",
       "        trade_order_count_mean  trade_log_return_realized_volatility_450  \\\n",
       "0                     2.750000                                  0.001060   \n",
       "1                     1.900000                                  0.000501   \n",
       "2                     2.720000                                  0.001048   \n",
       "3                     3.933333                                  0.000802   \n",
       "4                     4.045455                                  0.000360   \n",
       "...                        ...                                       ...   \n",
       "428927                2.783784                                  0.001058   \n",
       "428928                3.418605                                  0.001388   \n",
       "428929                2.800000                                  0.001244   \n",
       "428930                2.925000                                  0.001023   \n",
       "428931                3.000000                                  0.000466   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_450  trade_size_sum_450  \\\n",
       "0                                           14.0              1042.0   \n",
       "1                                           10.0               828.0   \n",
       "2                                            9.0              1085.0   \n",
       "3                                            3.0               514.0   \n",
       "4                                            4.0                43.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      12.0               491.0   \n",
       "428928                                      13.0               326.0   \n",
       "428929                                       6.0               348.0   \n",
       "428930                                      22.0              2300.0   \n",
       "428931                                       9.0              1873.0   \n",
       "\n",
       "        trade_order_count_mean_450  trade_log_return_realized_volatility_300  \\\n",
       "0                         2.642857                                  0.001308   \n",
       "1                         2.200000                                  0.000587   \n",
       "2                         3.666667                                  0.001137   \n",
       "3                         3.666667                                  0.001089   \n",
       "4                         3.500000                                  0.000453   \n",
       "...                            ...                                       ...   \n",
       "428927                    1.833333                                  0.001451   \n",
       "428928                    1.769231                                  0.001791   \n",
       "428929                    2.166667                                  0.001580   \n",
       "428930                    2.727273                                  0.001520   \n",
       "428931                    4.000000                                  0.000849   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                           21.0              1587.0   \n",
       "1                                           16.0               900.0   \n",
       "2                                           12.0              1189.0   \n",
       "3                                            9.0              1556.0   \n",
       "4                                           11.0              1219.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      18.0               796.0   \n",
       "428928                                      20.0              1107.0   \n",
       "428929                                      24.0              2750.0   \n",
       "428930                                      43.0              5150.0   \n",
       "428931                                      17.0              3010.0   \n",
       "\n",
       "        trade_order_count_mean_300  trade_log_return_realized_volatility_150  \\\n",
       "0                         2.571429                                  0.001701   \n",
       "1                         2.250000                                  0.000813   \n",
       "2                         3.166667                                  0.001621   \n",
       "3                         5.111111                                  0.001401   \n",
       "4                         4.909091                                  0.000550   \n",
       "...                            ...                                       ...   \n",
       "428927                    2.055556                                  0.001924   \n",
       "428928                    3.550000                                  0.002101   \n",
       "428929                    2.541667                                  0.001913   \n",
       "428930                    2.813953                                  0.001714   \n",
       "428931                    3.588235                                  0.001012   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_150  trade_size_sum_150  \\\n",
       "0                                           30.0              2069.0   \n",
       "1                                           24.0              1173.0   \n",
       "2                                           20.0              2010.0   \n",
       "3                                           11.0              1631.0   \n",
       "4                                           16.0              1570.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      27.0              1426.0   \n",
       "428928                                      31.0              1550.0   \n",
       "428929                                      31.0              3493.0   \n",
       "428930                                      62.0              7261.0   \n",
       "428931                                      29.0              4287.0   \n",
       "\n",
       "        trade_order_count_mean_150  \n",
       "0                         2.433333  \n",
       "1                         2.041667  \n",
       "2                         2.950000  \n",
       "3                         4.545455  \n",
       "4                         4.500000  \n",
       "...                            ...  \n",
       "428927                    2.259259  \n",
       "428928                    3.161290  \n",
       "428929                    2.838710  \n",
       "428930                    2.822581  \n",
       "428931                    3.034483  \n",
       "\n",
       "[428932 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:34:03.939678Z",
     "start_time": "2021-09-17T18:34:03.781960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>wap1_mean</th>\n",
       "      <th>log_return1_realized_volatility</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>wap_balance_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>wap1_mean_450</th>\n",
       "      <th>log_return1_realized_volatility_450</th>\n",
       "      <th>log_return2_realized_volatility_450</th>\n",
       "      <th>wap_balance_mean_450</th>\n",
       "      <th>price_spread_mean_450</th>\n",
       "      <th>bid_spread_mean_450</th>\n",
       "      <th>ask_spread_mean_450</th>\n",
       "      <th>total_volume_mean_450</th>\n",
       "      <th>volume_imbalance_mean_450</th>\n",
       "      <th>wap1_mean_300</th>\n",
       "      <th>log_return1_realized_volatility_300</th>\n",
       "      <th>log_return2_realized_volatility_300</th>\n",
       "      <th>wap_balance_mean_300</th>\n",
       "      <th>price_spread_mean_300</th>\n",
       "      <th>bid_spread_mean_300</th>\n",
       "      <th>ask_spread_mean_300</th>\n",
       "      <th>total_volume_mean_300</th>\n",
       "      <th>volume_imbalance_mean_300</th>\n",
       "      <th>wap1_mean_150</th>\n",
       "      <th>log_return1_realized_volatility_150</th>\n",
       "      <th>log_return2_realized_volatility_150</th>\n",
       "      <th>wap_balance_mean_150</th>\n",
       "      <th>price_spread_mean_150</th>\n",
       "      <th>bid_spread_mean_150</th>\n",
       "      <th>ask_spread_mean_150</th>\n",
       "      <th>total_volume_mean_150</th>\n",
       "      <th>volume_imbalance_mean_150</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_log_return_realized_volatility_450</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_450</th>\n",
       "      <th>trade_size_sum_450</th>\n",
       "      <th>trade_order_count_mean_450</th>\n",
       "      <th>trade_log_return_realized_volatility_300</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_300</th>\n",
       "      <th>trade_size_sum_300</th>\n",
       "      <th>trade_order_count_mean_300</th>\n",
       "      <th>trade_log_return_realized_volatility_150</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique_150</th>\n",
       "      <th>trade_size_sum_150</th>\n",
       "      <th>trade_order_count_mean_150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>1.003482</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>263.941176</td>\n",
       "      <td>141.470588</td>\n",
       "      <td>1.003753</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>294.928058</td>\n",
       "      <td>137.158273</td>\n",
       "      <td>1.003832</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>327.431034</td>\n",
       "      <td>123.586207</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1042.0</td>\n",
       "      <td>2.642857</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2069.0</td>\n",
       "      <td>2.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>1.000518</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>447.981481</td>\n",
       "      <td>97.685185</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>484.521739</td>\n",
       "      <td>135.513043</td>\n",
       "      <td>1.000301</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>419.277457</td>\n",
       "      <td>151.566474</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>10.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>2.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>0.998237</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>459.113636</td>\n",
       "      <td>156.113636</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>455.235294</td>\n",
       "      <td>144.147059</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>428.537815</td>\n",
       "      <td>132.084034</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>0.998079</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>0.998436</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>418.169811</td>\n",
       "      <td>144.698113</td>\n",
       "      <td>0.998464</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.003273</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>424.234568</td>\n",
       "      <td>151.765432</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>3.0</td>\n",
       "      <td>514.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>0.999518</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>391.944444</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>0.999488</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000120</td>\n",
       "      <td>407.584270</td>\n",
       "      <td>99.449438</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>371.266667</td>\n",
       "      <td>131.474074</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1219.0</td>\n",
       "      <td>4.909091</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1570.0</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>406.045161</td>\n",
       "      <td>161.638710</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000129</td>\n",
       "      <td>347.333333</td>\n",
       "      <td>119.466667</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>379.443662</td>\n",
       "      <td>150.471831</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.005201</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000181</td>\n",
       "      <td>412.590308</td>\n",
       "      <td>152.731278</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>2.783784</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>12.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>18.0</td>\n",
       "      <td>796.0</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1426.0</td>\n",
       "      <td>2.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>243.322870</td>\n",
       "      <td>150.578475</td>\n",
       "      <td>1.004174</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>232.462963</td>\n",
       "      <td>121.203704</td>\n",
       "      <td>1.003528</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>242.561905</td>\n",
       "      <td>153.819048</td>\n",
       "      <td>1.002893</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>225.834320</td>\n",
       "      <td>139.384615</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>3.418605</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>13.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>1.769231</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>3.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>348.093750</td>\n",
       "      <td>254.406250</td>\n",
       "      <td>1.001527</td>\n",
       "      <td>0.001551</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>344.459770</td>\n",
       "      <td>285.218391</td>\n",
       "      <td>1.001282</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>343.592814</td>\n",
       "      <td>249.401198</td>\n",
       "      <td>1.001142</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.005654</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>339.199005</td>\n",
       "      <td>246.313433</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>6.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3493.0</td>\n",
       "      <td>2.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>426.416040</td>\n",
       "      <td>145.654135</td>\n",
       "      <td>1.001663</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>470.470000</td>\n",
       "      <td>160.490000</td>\n",
       "      <td>1.001807</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>471.183246</td>\n",
       "      <td>159.832461</td>\n",
       "      <td>1.001855</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>453.528814</td>\n",
       "      <td>160.132203</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9389.0</td>\n",
       "      <td>2.925000</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5150.0</td>\n",
       "      <td>2.813953</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7261.0</td>\n",
       "      <td>2.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>531.313364</td>\n",
       "      <td>177.442396</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>626.537037</td>\n",
       "      <td>289.574074</td>\n",
       "      <td>1.000249</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>502.406250</td>\n",
       "      <td>212.052083</td>\n",
       "      <td>1.000203</td>\n",
       "      <td>0.001656</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>512.353741</td>\n",
       "      <td>185.986395</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3010.0</td>\n",
       "      <td>3.588235</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>3.034483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stock_id  wap1_mean  log_return1_realized_volatility  \\\n",
       "0              0   1.003725                         0.004499   \n",
       "1              0   1.000239                         0.001204   \n",
       "2              0   0.999542                         0.002369   \n",
       "3              0   0.998832                         0.002574   \n",
       "4              0   0.999619                         0.001894   \n",
       "...          ...        ...                              ...   \n",
       "428927       126   0.999582                         0.003691   \n",
       "428928       126   1.002476                         0.004104   \n",
       "428929       126   1.001082                         0.003117   \n",
       "428930       126   1.001809                         0.003661   \n",
       "428931       126   1.000272                         0.002092   \n",
       "\n",
       "        log_return2_realized_volatility  wap_balance_mean  price_spread_mean  \\\n",
       "0                              0.006999          0.000388           0.000852   \n",
       "1                              0.002476          0.000212           0.000394   \n",
       "2                              0.004801          0.000331           0.000725   \n",
       "3                              0.003637          0.000380           0.000860   \n",
       "4                              0.003257          0.000254           0.000397   \n",
       "...                                 ...               ...                ...   \n",
       "428927                         0.005876          0.000361           0.000878   \n",
       "428928                         0.004991          0.000295           0.000706   \n",
       "428929                         0.006020          0.000394           0.000739   \n",
       "428930                         0.005362          0.000231           0.000530   \n",
       "428931                         0.003037          0.000216           0.000432   \n",
       "\n",
       "        bid_spread_mean  ask_spread_mean  total_volume_mean  \\\n",
       "0              0.000176        -0.000151         323.496689   \n",
       "1              0.000142        -0.000135         411.450000   \n",
       "2              0.000197        -0.000198         416.351064   \n",
       "3              0.000190        -0.000108         435.266667   \n",
       "4              0.000191        -0.000109         343.221591   \n",
       "...                 ...              ...                ...   \n",
       "428927         0.000091        -0.000202         406.045161   \n",
       "428928         0.000126        -0.000142         243.322870   \n",
       "428929         0.000189        -0.000192         348.093750   \n",
       "428930         0.000143        -0.000134         426.416040   \n",
       "428931         0.000109        -0.000159         531.313364   \n",
       "\n",
       "        volume_imbalance_mean  wap1_mean_450  \\\n",
       "0                  134.894040       1.003482   \n",
       "1                  142.050000       1.000518   \n",
       "2                  141.414894       0.998237   \n",
       "3                  146.216667       0.998079   \n",
       "4                  123.846591       0.999518   \n",
       "...                       ...            ...   \n",
       "428927             161.638710       0.999301   \n",
       "428928             150.578475       1.004174   \n",
       "428929             254.406250       1.001527   \n",
       "428930             145.654135       1.001663   \n",
       "428931             177.442396       0.999967   \n",
       "\n",
       "        log_return1_realized_volatility_450  \\\n",
       "0                                  0.001721   \n",
       "1                                  0.000918   \n",
       "2                                  0.001158   \n",
       "3                                  0.000993   \n",
       "4                                  0.001378   \n",
       "...                                     ...   \n",
       "428927                             0.001701   \n",
       "428928                             0.002613   \n",
       "428929                             0.001551   \n",
       "428930                             0.001704   \n",
       "428931                             0.000952   \n",
       "\n",
       "        log_return2_realized_volatility_450  wap_balance_mean_450  \\\n",
       "0                                  0.004114              0.000366   \n",
       "1                                  0.001883              0.000269   \n",
       "2                                  0.002972              0.000365   \n",
       "3                                  0.001424              0.000358   \n",
       "4                                  0.000966              0.000364   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.002461              0.000338   \n",
       "428928                             0.002698              0.000278   \n",
       "428929                             0.003079              0.000455   \n",
       "428930                             0.001979              0.000190   \n",
       "428931                             0.001595              0.000217   \n",
       "\n",
       "        price_spread_mean_450  bid_spread_mean_450  ask_spread_mean_450  \\\n",
       "0                    0.000783             0.000262            -0.000166   \n",
       "1                    0.000348             0.000233            -0.000143   \n",
       "2                    0.000605             0.000186            -0.000208   \n",
       "3                    0.001058             0.000116            -0.000049   \n",
       "4                    0.000519             0.000196            -0.000136   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000840             0.000098            -0.000129   \n",
       "428928               0.000708             0.000101            -0.000179   \n",
       "428929               0.000657             0.000326            -0.000221   \n",
       "428930               0.000464             0.000138            -0.000130   \n",
       "428931               0.000461             0.000090            -0.000134   \n",
       "\n",
       "        total_volume_mean_450  volume_imbalance_mean_450  wap1_mean_300  \\\n",
       "0                  263.941176                 141.470588       1.003753   \n",
       "1                  447.981481                  97.685185       1.000397   \n",
       "2                  459.113636                 156.113636       0.998685   \n",
       "3                  540.000000                 146.000000       0.998436   \n",
       "4                  391.944444                 117.000000       0.999488   \n",
       "...                       ...                        ...            ...   \n",
       "428927             347.333333                 119.466667       0.999375   \n",
       "428928             232.462963                 121.203704       1.003528   \n",
       "428929             344.459770                 285.218391       1.001282   \n",
       "428930             470.470000                 160.490000       1.001807   \n",
       "428931             626.537037                 289.574074       1.000249   \n",
       "\n",
       "        log_return1_realized_volatility_300  \\\n",
       "0                                  0.002953   \n",
       "1                                  0.000981   \n",
       "2                                  0.001295   \n",
       "3                                  0.001776   \n",
       "4                                  0.001520   \n",
       "...                                     ...   \n",
       "428927                             0.002899   \n",
       "428928                             0.003454   \n",
       "428929                             0.002792   \n",
       "428930                             0.002379   \n",
       "428931                             0.001414   \n",
       "\n",
       "        log_return2_realized_volatility_300  wap_balance_mean_300  \\\n",
       "0                                  0.004863              0.000372   \n",
       "1                                  0.002009              0.000239   \n",
       "2                                  0.003196              0.000431   \n",
       "3                                  0.002713              0.000331   \n",
       "4                                  0.002188              0.000252   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.003776              0.000297   \n",
       "428928                             0.003402              0.000280   \n",
       "428929                             0.005387              0.000430   \n",
       "428930                             0.003182              0.000199   \n",
       "428931                             0.002457              0.000227   \n",
       "\n",
       "        price_spread_mean_300  bid_spread_mean_300  ask_spread_mean_300  \\\n",
       "0                    0.000822             0.000223            -0.000162   \n",
       "1                    0.000353             0.000164            -0.000123   \n",
       "2                    0.000689             0.000141            -0.000249   \n",
       "3                    0.000833             0.000158            -0.000095   \n",
       "4                    0.000425             0.000191            -0.000120   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000890             0.000091            -0.000162   \n",
       "428928               0.000729             0.000147            -0.000168   \n",
       "428929               0.000704             0.000244            -0.000200   \n",
       "428930               0.000493             0.000150            -0.000118   \n",
       "428931               0.000430             0.000108            -0.000164   \n",
       "\n",
       "        total_volume_mean_300  volume_imbalance_mean_300  wap1_mean_150  \\\n",
       "0                  294.928058                 137.158273       1.003832   \n",
       "1                  484.521739                 135.513043       1.000301   \n",
       "2                  455.235294                 144.147059       0.999126   \n",
       "3                  418.169811                 144.698113       0.998464   \n",
       "4                  407.584270                  99.449438       0.999618   \n",
       "...                       ...                        ...            ...   \n",
       "428927             379.443662                 150.471831       0.999375   \n",
       "428928             242.561905                 153.819048       1.002893   \n",
       "428929             343.592814                 249.401198       1.001142   \n",
       "428930             471.183246                 159.832461       1.001855   \n",
       "428931             502.406250                 212.052083       1.000203   \n",
       "\n",
       "        log_return1_realized_volatility_150  \\\n",
       "0                                  0.003796   \n",
       "1                                  0.001058   \n",
       "2                                  0.002138   \n",
       "3                                  0.002196   \n",
       "4                                  0.001609   \n",
       "...                                     ...   \n",
       "428927                             0.003438   \n",
       "428928                             0.003972   \n",
       "428929                             0.002955   \n",
       "428930                             0.003042   \n",
       "428931                             0.001656   \n",
       "\n",
       "        log_return2_realized_volatility_150  wap_balance_mean_150  \\\n",
       "0                                  0.006087              0.000397   \n",
       "1                                  0.002262              0.000205   \n",
       "2                                  0.004019              0.000373   \n",
       "3                                  0.003273              0.000362   \n",
       "4                                  0.002927              0.000242   \n",
       "...                                     ...                   ...   \n",
       "428927                             0.005201              0.000372   \n",
       "428928                             0.004569              0.000307   \n",
       "428929                             0.005654              0.000393   \n",
       "428930                             0.004462              0.000210   \n",
       "428931                             0.002595              0.000190   \n",
       "\n",
       "        price_spread_mean_150  bid_spread_mean_150  ask_spread_mean_150  \\\n",
       "0                    0.000858             0.000188            -0.000147   \n",
       "1                    0.000353             0.000141            -0.000127   \n",
       "2                    0.000679             0.000161            -0.000241   \n",
       "3                    0.000920             0.000170            -0.000108   \n",
       "4                    0.000395             0.000187            -0.000117   \n",
       "...                       ...                  ...                  ...   \n",
       "428927               0.000904             0.000090            -0.000181   \n",
       "428928               0.000726             0.000131            -0.000148   \n",
       "428929               0.000713             0.000211            -0.000199   \n",
       "428930               0.000513             0.000149            -0.000130   \n",
       "428931               0.000412             0.000098            -0.000154   \n",
       "\n",
       "        total_volume_mean_150  volume_imbalance_mean_150  \\\n",
       "0                  327.431034                 123.586207   \n",
       "1                  419.277457                 151.566474   \n",
       "2                  428.537815                 132.084034   \n",
       "3                  424.234568                 151.765432   \n",
       "4                  371.266667                 131.474074   \n",
       "...                       ...                        ...   \n",
       "428927             412.590308                 152.731278   \n",
       "428928             225.834320                 139.384615   \n",
       "428929             339.199005                 246.313433   \n",
       "428930             453.528814                 160.132203   \n",
       "428931             512.353741                 185.986395   \n",
       "\n",
       "        trade_log_return_realized_volatility  \\\n",
       "0                                   0.002006   \n",
       "1                                   0.000901   \n",
       "2                                   0.001961   \n",
       "3                                   0.001561   \n",
       "4                                   0.000871   \n",
       "...                                      ...   \n",
       "428927                              0.002171   \n",
       "428928                              0.002180   \n",
       "428929                              0.001921   \n",
       "428930                              0.002051   \n",
       "428931                              0.001041   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40.0          3179.0   \n",
       "1                                       30.0          1289.0   \n",
       "2                                       25.0          2161.0   \n",
       "3                                       15.0          1962.0   \n",
       "4                                       22.0          1791.0   \n",
       "...                                      ...             ...   \n",
       "428927                                  37.0          2570.0   \n",
       "428928                                  43.0          2323.0   \n",
       "428929                                  35.0          3740.0   \n",
       "428930                                  80.0          9389.0   \n",
       "428931                                  36.0          5325.0   \n",
       "\n",
       "        trade_order_count_mean  trade_log_return_realized_volatility_450  \\\n",
       "0                     2.750000                                  0.001060   \n",
       "1                     1.900000                                  0.000501   \n",
       "2                     2.720000                                  0.001048   \n",
       "3                     3.933333                                  0.000802   \n",
       "4                     4.045455                                  0.000360   \n",
       "...                        ...                                       ...   \n",
       "428927                2.783784                                  0.001058   \n",
       "428928                3.418605                                  0.001388   \n",
       "428929                2.800000                                  0.001244   \n",
       "428930                2.925000                                  0.001023   \n",
       "428931                3.000000                                  0.000466   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_450  trade_size_sum_450  \\\n",
       "0                                           14.0              1042.0   \n",
       "1                                           10.0               828.0   \n",
       "2                                            9.0              1085.0   \n",
       "3                                            3.0               514.0   \n",
       "4                                            4.0                43.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      12.0               491.0   \n",
       "428928                                      13.0               326.0   \n",
       "428929                                       6.0               348.0   \n",
       "428930                                      22.0              2300.0   \n",
       "428931                                       9.0              1873.0   \n",
       "\n",
       "        trade_order_count_mean_450  trade_log_return_realized_volatility_300  \\\n",
       "0                         2.642857                                  0.001308   \n",
       "1                         2.200000                                  0.000587   \n",
       "2                         3.666667                                  0.001137   \n",
       "3                         3.666667                                  0.001089   \n",
       "4                         3.500000                                  0.000453   \n",
       "...                            ...                                       ...   \n",
       "428927                    1.833333                                  0.001451   \n",
       "428928                    1.769231                                  0.001791   \n",
       "428929                    2.166667                                  0.001580   \n",
       "428930                    2.727273                                  0.001520   \n",
       "428931                    4.000000                                  0.000849   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_300  trade_size_sum_300  \\\n",
       "0                                           21.0              1587.0   \n",
       "1                                           16.0               900.0   \n",
       "2                                           12.0              1189.0   \n",
       "3                                            9.0              1556.0   \n",
       "4                                           11.0              1219.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      18.0               796.0   \n",
       "428928                                      20.0              1107.0   \n",
       "428929                                      24.0              2750.0   \n",
       "428930                                      43.0              5150.0   \n",
       "428931                                      17.0              3010.0   \n",
       "\n",
       "        trade_order_count_mean_300  trade_log_return_realized_volatility_150  \\\n",
       "0                         2.571429                                  0.001701   \n",
       "1                         2.250000                                  0.000813   \n",
       "2                         3.166667                                  0.001621   \n",
       "3                         5.111111                                  0.001401   \n",
       "4                         4.909091                                  0.000550   \n",
       "...                            ...                                       ...   \n",
       "428927                    2.055556                                  0.001924   \n",
       "428928                    3.550000                                  0.002101   \n",
       "428929                    2.541667                                  0.001913   \n",
       "428930                    2.813953                                  0.001714   \n",
       "428931                    3.588235                                  0.001012   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique_150  trade_size_sum_150  \\\n",
       "0                                           30.0              2069.0   \n",
       "1                                           24.0              1173.0   \n",
       "2                                           20.0              2010.0   \n",
       "3                                           11.0              1631.0   \n",
       "4                                           16.0              1570.0   \n",
       "...                                          ...                 ...   \n",
       "428927                                      27.0              1426.0   \n",
       "428928                                      31.0              1550.0   \n",
       "428929                                      31.0              3493.0   \n",
       "428930                                      62.0              7261.0   \n",
       "428931                                      29.0              4287.0   \n",
       "\n",
       "        trade_order_count_mean_150  \n",
       "0                         2.433333  \n",
       "1                         2.041667  \n",
       "2                         2.950000  \n",
       "3                         4.545455  \n",
       "4                         4.500000  \n",
       "...                            ...  \n",
       "428927                    2.259259  \n",
       "428928                    3.161290  \n",
       "428929                    2.838710  \n",
       "428930                    2.822581  \n",
       "428931                    3.034483  \n",
       "\n",
       "[428932 rows x 53 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.keys().tolist()\n",
    "[columns.pop(columns.index(c)) for c in  ['time_id', 'row_id', 'target']]\n",
    "\n",
    "y_data = df['target']\n",
    "x_data = df[columns]\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:34:14.957260Z",
     "start_time": "2021-09-17T18:34:14.818670Z"
    }
   },
   "outputs": [],
   "source": [
    "kfd = StratifiedKFold(5)\n",
    "for trn_idx, val_idx in kfd.split(df, y=df.stock_id, groups=df.time_id):\n",
    "    break\n",
    "    \n",
    "x_trn = x_data.iloc[trn_idx]\n",
    "y_trn = y_data.iloc[trn_idx]\n",
    "\n",
    "x_val = x_data.iloc[val_idx]\n",
    "y_val = y_data.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-17T18:34:37.983701Z",
     "start_time": "2021-09-17T18:34:37.978822Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def optuna_lgbm(x_train,\n",
    "                y_train,\n",
    "                x_valid,\n",
    "                y_valid,\n",
    "                params: dict = None,\n",
    "                verbose=100):\n",
    "    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n",
    "    trains = lgbm.Dataset(x_train, y_train)\n",
    "    valids = lgbm.Dataset(x_valid, y_valid)\n",
    "    model = lgbm.train(params,\n",
    "                       trains,\n",
    "                       valid_sets=valids,\n",
    "                       num_boost_round=10000,\n",
    "                       verbose_eval=False,\n",
    "                       early_stopping_rounds=100)\n",
    "    best_params = model.params\n",
    "    oof_pred = model.predict(x_valid)\n",
    "    score = rmspe(oof_pred, y_valid)\n",
    "    print('rmspe:', score)\n",
    "    return oof_pred, model, score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T06:17:42.299932Z",
     "start_time": "2021-09-17T19:22:52.736141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-09-18 03:22:52,739]\u001b[0m A new study created in memory with name: no-name-b5f69f18-c7ca-4562-a0ea-42469e010650\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:   0%|                                                     | 0/7 [03:26<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  14%|######2                                     | 1/7 [03:26<20:37, 206.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 03:26:18,954]\u001b[0m Trial 0 finished with value: 0.0007211200302020454 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.0007211200302020454.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  14%|######2                                     | 1/7 [03:26<20:37, 206.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  14%|######2                                     | 1/7 [11:43<20:37, 206.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  29%|############5                               | 2/7 [11:43<24:27, 293.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 03:34:36,018]\u001b[0m Trial 1 finished with value: 0.0007209748606336821 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.0007209748606336821.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  29%|############5                               | 2/7 [11:43<24:27, 293.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  29%|############5                               | 2/7 [15:38<24:27, 293.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  43%|##################8                         | 3/7 [15:38<18:23, 275.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 03:38:31,028]\u001b[0m Trial 2 finished with value: 0.0007219086157598064 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.0007209748606336821.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  43%|##################8                         | 3/7 [15:38<18:23, 275.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  43%|##################8                         | 3/7 [21:58<18:23, 275.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  57%|#########################1                  | 4/7 [21:58<15:21, 307.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 03:44:51,036]\u001b[0m Trial 3 finished with value: 0.0007209045602739178 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.0007209045602739178.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  57%|#########################1                  | 4/7 [21:58<15:21, 307.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  57%|#########################1                  | 4/7 [35:59<15:21, 307.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  71%|###############################4            | 5/7 [35:59<15:35, 467.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 03:58:52,728]\u001b[0m Trial 4 finished with value: 0.0007211381642186495 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.0007209045602739178.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  71%|###############################4            | 5/7 [35:59<15:35, 467.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  71%|###############################4            | 5/7 [39:40<15:35, 467.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  86%|#####################################7      | 6/7 [39:40<06:33, 393.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:02:32,878]\u001b[0m Trial 5 finished with value: 0.0007219116515106306 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.0007209045602739178.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  86%|#####################################7      | 6/7 [39:40<06:33, 393.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721:  86%|#####################################7      | 6/7 [46:23<06:33, 393.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.000721: 100%|############################################| 7/7 [46:23<00:00, 396.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:09:16,481]\u001b[0m Trial 6 finished with value: 0.0007209115486934998 and parameters: {'feature_fraction': 0.6}. Best is trial 3 with value: 0.0007209045602739178.\u001b[0m\n",
      "feature_fraction, val_score: 0.000721: 100%|############################################| 7/7 [46:23<00:00, 397.68s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:   0%|                                                          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:   0%|                                                          | 0/20 [02:28<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:   5%|##4                                              | 1/20 [02:28<46:56, 148.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:11:44,751]\u001b[0m Trial 7 finished with value: 0.0007210016118144021 and parameters: {'num_leaves': 125}. Best is trial 7 with value: 0.0007210016118144021.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:   5%|##4                                              | 1/20 [02:28<46:56, 148.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:   5%|##4                                              | 1/20 [04:20<46:56, 148.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  10%|####9                                            | 2/20 [04:20<41:13, 137.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:13:36,846]\u001b[0m Trial 8 finished with value: 0.0007217822215343885 and parameters: {'num_leaves': 215}. Best is trial 7 with value: 0.0007210016118144021.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  10%|####9                                            | 2/20 [04:20<41:13, 137.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  10%|####9                                            | 2/20 [06:18<41:13, 137.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  15%|#######3                                         | 3/20 [06:18<37:16, 131.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:15:34,776]\u001b[0m Trial 9 finished with value: 0.0007216936200575185 and parameters: {'num_leaves': 153}. Best is trial 7 with value: 0.0007210016118144021.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  15%|#######3                                         | 3/20 [06:18<37:16, 131.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  15%|#######3                                         | 3/20 [09:29<37:16, 131.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  20%|#########8                                       | 4/20 [09:29<39:53, 149.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:18:46,456]\u001b[0m Trial 10 finished with value: 0.0007211665905293567 and parameters: {'num_leaves': 89}. Best is trial 7 with value: 0.0007210016118144021.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  20%|#########8                                       | 4/20 [09:29<39:53, 149.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  20%|#########8                                       | 4/20 [20:41<39:53, 149.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  25%|###########7                                   | 5/20 [20:41<1:16:33, 306.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:29:58,183]\u001b[0m Trial 11 finished with value: 0.0007205875753540014 and parameters: {'num_leaves': 22}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  25%|###########7                                   | 5/20 [20:41<1:16:33, 306.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  25%|###########7                                   | 5/20 [26:18<1:16:33, 306.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  30%|##############1                                | 6/20 [26:18<1:13:34, 315.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:35:34,631]\u001b[0m Trial 12 finished with value: 0.0007214325096172281 and parameters: {'num_leaves': 24}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  30%|##############1                                | 6/20 [26:18<1:13:34, 315.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  30%|##############1                                | 6/20 [32:34<1:13:34, 315.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  35%|################4                              | 7/20 [32:34<1:12:18, 333.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:41:51,300]\u001b[0m Trial 13 finished with value: 0.0007209968016898364 and parameters: {'num_leaves': 34}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  35%|################4                              | 7/20 [32:34<1:12:18, 333.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  35%|################4                              | 7/20 [34:31<1:12:18, 333.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  40%|###################6                             | 8/20 [34:31<53:42, 268.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:43:47,764]\u001b[0m Trial 14 finished with value: 0.0007215005379330141 and parameters: {'num_leaves': 117}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  40%|###################6                             | 8/20 [34:31<53:42, 268.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  40%|###################6                             | 8/20 [37:26<53:42, 268.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  45%|######################                           | 9/20 [37:26<44:05, 240.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:46:42,841]\u001b[0m Trial 15 finished with value: 0.0007214875154770621 and parameters: {'num_leaves': 110}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  45%|######################                           | 9/20 [37:26<44:05, 240.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  45%|######################                           | 9/20 [40:45<44:05, 240.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  50%|########################                        | 10/20 [40:45<38:02, 228.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 04:50:02,346]\u001b[0m Trial 16 finished with value: 0.0007214799543890699 and parameters: {'num_leaves': 94}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  50%|########################                        | 10/20 [40:45<38:02, 228.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  50%|#######################                       | 10/20 [1:00:16<38:02, 228.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  55%|########################2                   | 11/20 [1:00:16<1:16:38, 510.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:09:32,959]\u001b[0m Trial 17 finished with value: 0.0007486892764770925 and parameters: {'num_leaves': 2}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  55%|########################2                   | 11/20 [1:00:16<1:16:38, 510.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  55%|########################2                   | 11/20 [1:03:27<1:16:38, 510.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  60%|###########################6                  | 12/20 [1:03:27<55:20, 415.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:12:44,453]\u001b[0m Trial 18 finished with value: 0.0007221305276969322 and parameters: {'num_leaves': 52}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  60%|###########################6                  | 12/20 [1:03:27<55:20, 415.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  60%|###########################6                  | 12/20 [1:07:59<55:20, 415.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  65%|#############################9                | 13/20 [1:07:59<43:24, 372.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:17:15,908]\u001b[0m Trial 19 finished with value: 0.0007216475780033921 and parameters: {'num_leaves': 45}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  65%|#############################9                | 13/20 [1:07:59<43:24, 372.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  65%|#############################9                | 13/20 [1:15:41<43:24, 372.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  70%|################################1             | 14/20 [1:15:41<39:53, 398.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:24:57,516]\u001b[0m Trial 20 finished with value: 0.0007210137699965267 and parameters: {'num_leaves': 19}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  70%|################################1             | 14/20 [1:15:41<39:53, 398.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  70%|################################1             | 14/20 [1:17:43<39:53, 398.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  75%|##################################5           | 15/20 [1:17:43<26:20, 316.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:27:00,281]\u001b[0m Trial 21 finished with value: 0.0007211350911366642 and parameters: {'num_leaves': 174}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  75%|##################################5           | 15/20 [1:17:43<26:20, 316.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  75%|##################################5           | 15/20 [1:20:55<26:20, 316.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  80%|####################################8         | 16/20 [1:20:55<18:34, 278.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:30:11,921]\u001b[0m Trial 22 finished with value: 0.0007210676893203447 and parameters: {'num_leaves': 61}. Best is trial 11 with value: 0.0007205875753540014.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000721:  80%|####################################8         | 16/20 [1:20:55<18:34, 278.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  80%|####################################8         | 16/20 [1:35:09<18:34, 278.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  85%|#######################################1      | 17/20 [1:35:09<22:33, 451.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:44:25,763]\u001b[0m Trial 23 finished with value: 0.0007202035019089275 and parameters: {'num_leaves': 12}. Best is trial 23 with value: 0.0007202035019089275.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  85%|#######################################1      | 17/20 [1:35:09<22:33, 451.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  85%|#######################################1      | 17/20 [1:46:06<22:33, 451.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  90%|#########################################4    | 18/20 [1:46:06<17:06, 513.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:55:23,176]\u001b[0m Trial 24 finished with value: 0.0007203799392574466 and parameters: {'num_leaves': 9}. Best is trial 23 with value: 0.0007202035019089275.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  90%|#########################################4    | 18/20 [1:46:06<17:06, 513.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  90%|#########################################4    | 18/20 [1:50:35<17:06, 513.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  95%|###########################################6  | 19/20 [1:50:35<07:19, 439.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 05:59:51,895]\u001b[0m Trial 25 finished with value: 0.0007209351288327666 and parameters: {'num_leaves': 256}. Best is trial 23 with value: 0.0007202035019089275.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  95%|###########################################6  | 19/20 [1:50:35<07:19, 439.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720:  95%|###########################################6  | 19/20 [1:54:41<07:19, 439.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.000720: 100%|##############################################| 20/20 [1:54:41<00:00, 381.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:03:57,995]\u001b[0m Trial 26 finished with value: 0.0007212624703748292 and parameters: {'num_leaves': 75}. Best is trial 23 with value: 0.0007202035019089275.\u001b[0m\n",
      "num_leaves, val_score: 0.000720: 100%|##############################################| 20/20 [1:54:41<00:00, 344.08s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000720:   0%|                                                             | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000719:   0%|                                                             | 0/10 [13:21<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000719:  10%|#####                                             | 1/10 [13:21<2:00:14, 801.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:17:19,618]\u001b[0m Trial 27 finished with value: 0.0007186507514199853 and parameters: {'bagging_fraction': 0.6745006430447457, 'bagging_freq': 6}. Best is trial 27 with value: 0.0007186507514199853.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000719:  10%|#####                                             | 1/10 [13:21<2:00:14, 801.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  10%|#####                                             | 1/10 [26:19<2:00:14, 801.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  20%|##########                                        | 2/10 [26:19<1:45:55, 794.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:30:17,517]\u001b[0m Trial 28 finished with value: 0.0007181202033130272 and parameters: {'bagging_fraction': 0.931072408888977, 'bagging_freq': 2}. Best is trial 28 with value: 0.0007181202033130272.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  20%|##########                                        | 2/10 [26:19<1:45:55, 794.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  20%|##########                                        | 2/10 [32:28<1:45:55, 794.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  30%|###############                                   | 3/10 [32:28<1:17:48, 666.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:36:26,611]\u001b[0m Trial 29 finished with value: 0.000719482813485659 and parameters: {'bagging_fraction': 0.4737653435969977, 'bagging_freq': 1}. Best is trial 28 with value: 0.0007181202033130272.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  30%|###############                                   | 3/10 [32:28<1:17:48, 666.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  30%|###############                                   | 3/10 [35:17<1:17:48, 666.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  40%|####################8                               | 4/10 [35:17<51:45, 517.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:39:15,601]\u001b[0m Trial 30 finished with value: 0.0007219687943460109 and parameters: {'bagging_fraction': 0.42124536265348644, 'bagging_freq': 2}. Best is trial 28 with value: 0.0007181202033130272.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  40%|####################8                               | 4/10 [35:17<51:45, 517.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  40%|####################8                               | 4/10 [43:54<51:45, 517.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  50%|##########################                          | 5/10 [43:54<43:06, 517.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:47:52,586]\u001b[0m Trial 31 finished with value: 0.0007180144886188703 and parameters: {'bagging_fraction': 0.6594436605515132, 'bagging_freq': 1}. Best is trial 31 with value: 0.0007180144886188703.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  50%|##########################                          | 5/10 [43:54<43:06, 517.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  50%|##########################                          | 5/10 [49:48<43:06, 517.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  60%|###############################2                    | 6/10 [49:48<31:13, 468.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 06:53:46,369]\u001b[0m Trial 32 finished with value: 0.0007201695002391187 and parameters: {'bagging_fraction': 0.5445922098247709, 'bagging_freq': 3}. Best is trial 31 with value: 0.0007180144886188703.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  60%|###############################2                    | 6/10 [49:48<31:13, 468.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  60%|##############################                    | 6/10 [1:06:09<31:13, 468.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  70%|###################################               | 7/10 [1:06:09<31:06, 622.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 07:10:07,738]\u001b[0m Trial 33 finished with value: 0.000718926683065849 and parameters: {'bagging_fraction': 0.9854094908647594, 'bagging_freq': 3}. Best is trial 31 with value: 0.0007180144886188703.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  70%|###################################               | 7/10 [1:06:09<31:06, 622.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  70%|###################################               | 7/10 [1:15:01<31:06, 622.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  80%|########################################          | 8/10 [1:15:01<19:50, 595.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 07:18:59,538]\u001b[0m Trial 34 finished with value: 0.0007197953335037868 and parameters: {'bagging_fraction': 0.5050899571350083, 'bagging_freq': 5}. Best is trial 31 with value: 0.0007180144886188703.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  80%|########################################          | 8/10 [1:15:01<19:50, 595.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  80%|########################################          | 8/10 [1:27:24<19:50, 595.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  90%|#############################################     | 9/10 [1:27:24<10:39, 639.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 07:31:22,255]\u001b[0m Trial 35 finished with value: 0.0007177020023412288 and parameters: {'bagging_fraction': 0.7795709311102954, 'bagging_freq': 2}. Best is trial 35 with value: 0.0007177020023412288.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  90%|#############################################     | 9/10 [1:27:24<10:39, 639.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718:  90%|#############################################     | 9/10 [1:39:30<10:39, 639.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "bagging, val_score: 0.000718: 100%|#################################################| 10/10 [1:39:30<00:00, 665.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 07:43:28,934]\u001b[0m Trial 36 finished with value: 0.000718247028063815 and parameters: {'bagging_fraction': 0.8617321415778918, 'bagging_freq': 1}. Best is trial 35 with value: 0.0007177020023412288.\u001b[0m\n",
      "bagging, val_score: 0.000718: 100%|#################################################| 10/10 [1:39:30<00:00, 597.09s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:   0%|                                              | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:   0%|                                              | 0/6 [13:50<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:  17%|#####8                             | 1/6 [13:50<1:09:11, 830.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 07:57:19,257]\u001b[0m Trial 37 finished with value: 0.0007187655786911299 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.0007187655786911299.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:  17%|#####8                             | 1/6 [13:50<1:09:11, 830.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:  17%|#####8                             | 1/6 [26:18<1:09:11, 830.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:  33%|############3                        | 2/6 [26:18<53:42, 805.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 08:09:47,649]\u001b[0m Trial 38 finished with value: 0.0007176561351889795 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.0007176561351889795.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000718:  33%|############3                        | 2/6 [26:18<53:42, 805.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  33%|############3                        | 2/6 [41:43<53:42, 805.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  50%|##################5                  | 3/6 [41:43<42:04, 841.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 08:25:12,892]\u001b[0m Trial 39 finished with value: 0.0007174702440338705 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.0007174702440338705.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  50%|##################5                  | 3/6 [41:43<42:04, 841.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  50%|##################5                  | 3/6 [54:18<42:04, 841.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  67%|########################6            | 4/6 [54:18<27:10, 815.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 08:37:47,532]\u001b[0m Trial 40 finished with value: 0.0007177020023412288 and parameters: {'feature_fraction': 0.516}. Best is trial 39 with value: 0.0007174702440338705.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  67%|########################6            | 4/6 [54:18<27:10, 815.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  67%|#######################3           | 4/6 [1:04:41<27:10, 815.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  83%|#############################1     | 5/6 [1:04:41<12:37, 757.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 08:48:10,044]\u001b[0m Trial 41 finished with value: 0.0007178158485246756 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.0007174702440338705.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  83%|#############################1     | 5/6 [1:04:41<12:37, 757.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717:  83%|#############################1     | 5/6 [1:17:31<12:37, 757.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.000717: 100%|###################################| 6/6 [1:17:31<00:00, 761.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 09:01:00,379]\u001b[0m Trial 42 finished with value: 0.0007177682794856698 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 39 with value: 0.0007174702440338705.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.000717: 100%|###################################| 6/6 [1:17:31<00:00, 775.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:   0%|                                              | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:   0%|                                              | 0/20 [12:23<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:   5%|#7                                 | 1/20 [12:23<3:55:19, 743.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 09:13:23,518]\u001b[0m Trial 43 finished with value: 0.000717928653377278 and parameters: {'lambda_l1': 0.25470946006258993, 'lambda_l2': 2.306431042901154}. Best is trial 43 with value: 0.000717928653377278.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:   5%|#7                                 | 1/20 [12:23<3:55:19, 743.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:   5%|#7                                 | 1/20 [27:33<3:55:19, 743.11s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  10%|###5                               | 2/20 [27:33<3:58:00, 793.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 09:28:34,040]\u001b[0m Trial 44 finished with value: 0.0007175733762777658 and parameters: {'lambda_l1': 1.1121767450454947e-06, 'lambda_l2': 1.3390308888566978e-07}. Best is trial 44 with value: 0.0007175733762777658.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  10%|###5                               | 2/20 [27:33<3:58:00, 793.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  10%|###5                               | 2/20 [37:47<3:58:00, 793.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  15%|#####2                             | 3/20 [37:47<3:29:29, 739.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 09:38:47,606]\u001b[0m Trial 45 finished with value: 0.000717906698368006 and parameters: {'lambda_l1': 3.188644094479757e-05, 'lambda_l2': 0.008102415808675725}. Best is trial 44 with value: 0.0007175733762777658.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  15%|#####2                             | 3/20 [37:47<3:29:29, 739.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  15%|#####2                             | 3/20 [51:23<3:29:29, 739.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  20%|#######                            | 4/20 [51:23<3:23:17, 762.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 09:52:23,411]\u001b[0m Trial 46 finished with value: 0.0007177008691833884 and parameters: {'lambda_l1': 1.2204574321921039e-05, 'lambda_l2': 7.003571767295894e-08}. Best is trial 44 with value: 0.0007175733762777658.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  20%|#######                            | 4/20 [51:23<3:23:17, 762.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  20%|######6                          | 4/20 [1:01:42<3:23:17, 762.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  25%|########2                        | 5/20 [1:01:42<2:59:54, 719.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 10:02:43,394]\u001b[0m Trial 47 finished with value: 0.0007173146546617769 and parameters: {'lambda_l1': 6.021073149968654e-05, 'lambda_l2': 4.71170205321551}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  25%|########2                        | 5/20 [1:01:43<2:59:54, 719.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  25%|########2                        | 5/20 [1:10:46<2:59:54, 719.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  30%|#########9                       | 6/20 [1:10:46<2:35:36, 666.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 10:11:47,155]\u001b[0m Trial 48 finished with value: 0.0007187068831308609 and parameters: {'lambda_l1': 0.10973067653675421, 'lambda_l2': 1.5424127620701133e-05}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  30%|#########9                       | 6/20 [1:10:46<2:35:36, 666.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  30%|#########9                       | 6/20 [1:27:25<2:35:36, 666.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  35%|###########5                     | 7/20 [1:27:25<2:46:02, 766.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 10:28:25,610]\u001b[0m Trial 49 finished with value: 0.0007184261836908994 and parameters: {'lambda_l1': 0.019255773860736323, 'lambda_l2': 0.052089488784346646}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  35%|###########5                     | 7/20 [1:27:25<2:46:02, 766.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  35%|###########5                     | 7/20 [1:41:28<2:46:02, 766.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  40%|#############2                   | 8/20 [1:41:28<2:37:53, 789.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 10:42:28,917]\u001b[0m Trial 50 finished with value: 0.0007176931602562036 and parameters: {'lambda_l1': 0.002404667949496194, 'lambda_l2': 4.5796026876500415e-05}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  40%|#############2                   | 8/20 [1:41:28<2:37:53, 789.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  40%|#############2                   | 8/20 [1:54:53<2:37:53, 789.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  45%|##############8                  | 9/20 [1:54:53<2:25:34, 794.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 10:55:53,808]\u001b[0m Trial 51 finished with value: 0.0007178059728155693 and parameters: {'lambda_l1': 1.731441135627219e-06, 'lambda_l2': 2.46817008823503e-07}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  45%|##############8                  | 9/20 [1:54:53<2:25:34, 794.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  45%|##############8                  | 9/20 [2:06:52<2:25:34, 794.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  50%|################                | 10/20 [2:06:52<2:08:34, 771.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 11:07:52,588]\u001b[0m Trial 52 finished with value: 0.000718065954821825 and parameters: {'lambda_l1': 0.41778839857920935, 'lambda_l2': 1.61673746773745e-08}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  50%|################                | 10/20 [2:06:52<2:08:34, 771.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  50%|################                | 10/20 [2:18:26<2:08:34, 771.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  55%|#################6              | 11/20 [2:18:26<1:52:15, 748.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 11:19:27,122]\u001b[0m Trial 53 finished with value: 0.0007174956324188445 and parameters: {'lambda_l1': 2.6125159605972352e-08, 'lambda_l2': 9.579291488877228}. Best is trial 47 with value: 0.0007173146546617769.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  55%|#################6              | 11/20 [2:18:26<1:52:15, 748.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  55%|#################6              | 11/20 [2:29:42<1:52:15, 748.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  60%|###################2            | 12/20 [2:29:42<1:36:53, 726.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 11:30:43,208]\u001b[0m Trial 54 finished with value: 0.0007172945503718692 and parameters: {'lambda_l1': 2.1673303352874444e-08, 'lambda_l2': 8.125714708677291}. Best is trial 54 with value: 0.0007172945503718692.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  60%|###################2            | 12/20 [2:29:42<1:36:53, 726.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  60%|###################2            | 12/20 [2:44:02<1:36:53, 726.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  65%|####################8           | 13/20 [2:44:02<1:29:25, 766.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 11:45:02,679]\u001b[0m Trial 55 finished with value: 0.0007174894620287711 and parameters: {'lambda_l1': 1.624898841704704e-08, 'lambda_l2': 0.49063269361057754}. Best is trial 54 with value: 0.0007172945503718692.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  65%|####################8           | 13/20 [2:44:02<1:29:25, 766.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  65%|####################8           | 13/20 [2:56:07<1:29:25, 766.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  70%|######################4         | 14/20 [2:56:07<1:15:25, 754.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 11:57:08,081]\u001b[0m Trial 56 finished with value: 0.0007172565065709897 and parameters: {'lambda_l1': 0.0005196239469522688, 'lambda_l2': 0.004330909598772798}. Best is trial 56 with value: 0.0007172565065709897.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  70%|######################4         | 14/20 [2:56:07<1:15:25, 754.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  70%|######################4         | 14/20 [3:12:19<1:15:25, 754.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  75%|########################        | 15/20 [3:12:19<1:08:17, 819.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 12:13:20,061]\u001b[0m Trial 57 finished with value: 0.0007173007654568446 and parameters: {'lambda_l1': 0.0008973677797632322, 'lambda_l2': 0.0020092222822061458}. Best is trial 56 with value: 0.0007172565065709897.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000717:  75%|########################        | 15/20 [3:12:19<1:08:17, 819.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  75%|########################        | 15/20 [3:24:06<1:08:17, 819.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  80%|###########################2      | 16/20 [3:24:06<52:23, 785.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 12:25:07,322]\u001b[0m Trial 58 finished with value: 0.0007159474917333619 and parameters: {'lambda_l1': 5.76040714186739, 'lambda_l2': 0.1435657105138137}. Best is trial 58 with value: 0.0007159474917333619.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  80%|###########################2      | 16/20 [3:24:06<52:23, 785.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  80%|###########################2      | 16/20 [3:36:50<52:23, 785.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  85%|############################9     | 17/20 [3:36:50<38:57, 779.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 12:37:50,990]\u001b[0m Trial 59 finished with value: 0.0007172297076631301 and parameters: {'lambda_l1': 1.9147935840001056, 'lambda_l2': 0.1383360663634837}. Best is trial 58 with value: 0.0007159474917333619.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  85%|############################9     | 17/20 [3:36:50<38:57, 779.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  85%|############################9     | 17/20 [3:54:09<38:57, 779.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  90%|##############################6   | 18/20 [3:54:09<28:34, 857.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 12:55:10,109]\u001b[0m Trial 60 finished with value: 0.0007175312802611412 and parameters: {'lambda_l1': 3.415525943408919, 'lambda_l2': 0.1774087690323091}. Best is trial 58 with value: 0.0007159474917333619.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  90%|##############################6   | 18/20 [3:54:09<28:34, 857.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  90%|##############################6   | 18/20 [4:04:47<28:34, 857.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  95%|################################3 | 19/20 [4:04:47<13:11, 791.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 13:05:47,531]\u001b[0m Trial 61 finished with value: 0.0007168398936299654 and parameters: {'lambda_l1': 6.672482236548315, 'lambda_l2': 0.07408954500600338}. Best is trial 58 with value: 0.0007159474917333619.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  95%|################################3 | 19/20 [4:04:47<13:11, 791.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716:  95%|################################3 | 19/20 [4:15:15<13:11, 791.25s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.000716: 100%|##################################| 20/20 [4:15:15<00:00, 742.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 13:16:16,351]\u001b[0m Trial 62 finished with value: 0.0007168949974616045 and parameters: {'lambda_l1': 6.555076402377365, 'lambda_l2': 0.0005867728092401004}. Best is trial 58 with value: 0.0007159474917333619.\u001b[0m\n",
      "regularization_factors, val_score: 0.000716: 100%|##################################| 20/20 [4:15:15<00:00, 765.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:   0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:   0%|                                                     | 0/5 [12:06<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  20%|########8                                   | 1/5 [12:06<48:25, 726.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 13:28:22,823]\u001b[0m Trial 63 finished with value: 0.0007163296137497902 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.0007163296137497902.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  20%|########8                                   | 1/5 [12:06<48:25, 726.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  20%|########8                                   | 1/5 [26:16<48:25, 726.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  40%|#################6                          | 2/5 [26:16<38:10, 763.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 13:42:33,133]\u001b[0m Trial 64 finished with value: 0.0007165012851149946 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.0007163296137497902.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  40%|#################6                          | 2/5 [26:16<38:10, 763.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  40%|#################6                          | 2/5 [41:57<38:10, 763.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  60%|##########################4                 | 3/5 [41:57<27:13, 816.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 13:58:14,143]\u001b[0m Trial 65 finished with value: 0.0007159754394255936 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.0007159754394255936.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  60%|##########################4                 | 3/5 [41:57<27:13, 816.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  60%|##########################4                 | 3/5 [52:07<27:13, 816.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  80%|###################################2        | 4/5 [52:07<12:34, 754.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 14:08:24,167]\u001b[0m Trial 66 finished with value: 0.0007171126904731908 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.0007159754394255936.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  80%|###################################2        | 4/5 [52:07<12:34, 754.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met 'abs(label) < 1', will convert them to '1' in MAPE objective and metric\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13268\n",
      "[LightGBM] [Info] Number of data points in the train set: 343145, number of used features: 53\n",
      "[LightGBM] [Info] Start training from score 0.003036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716:  80%|#################################6        | 4/5 [1:01:21<12:34, 754.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.000716: 100%|##########################################| 5/5 [1:01:21<00:00, 694.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[32m[I 2021-09-18 14:17:37,743]\u001b[0m Trial 67 finished with value: 0.0007171095327514111 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.0007159754394255936.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.000716: 100%|##########################################| 5/5 [1:01:21<00:00, 736.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmspe: 0.26350891041127483\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'objective': 'mape',\n",
    "        'metric': 'mape',\n",
    "        'num_iterations': 10000,\n",
    "        'early_stopping_round': 500,\n",
    "        'n_jobs':6\n",
    "    }\n",
    "\n",
    "_, model, score, best_params = optuna_lgbm(x_trn, y_trn,\n",
    "                                           x_val, y_val, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T06:17:42.307740Z",
     "start_time": "2021-09-18T06:17:42.301884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'mape',\n",
       " 'metric': 'mape',\n",
       " 'n_jobs': 6,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 5.76040714186739,\n",
       " 'lambda_l2': 0.1435657105138137,\n",
       " 'num_leaves': 12,\n",
       " 'feature_fraction': 0.484,\n",
       " 'bagging_fraction': 0.7795709311102954,\n",
       " 'bagging_freq': 2,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 10000,\n",
       " 'early_stopping_round': 500}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T07:14:58.000209Z",
     "start_time": "2021-09-18T07:14:57.779628Z"
    }
   },
   "outputs": [],
   "source": [
    "save_pickle(model, 'cv2635089_col53_win150_300_450.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-18T07:12:08.908280Z",
     "start_time": "2021-09-18T07:12:08.903399Z"
    }
   },
   "outputs": [],
   "source": [
    "# pickle\n",
    "def save_pickle(dic, save_path):\n",
    "    import pickle\n",
    "    with open(save_path, 'wb') as f:\n",
    "        # with gzip.open(save_path, 'wb') as f:\n",
    "        pickle.dump(dic, f)\n",
    "\n",
    "\n",
    "def load_pickle(load_path):\n",
    "    import pickle\n",
    "    with open(load_path, 'rb') as f:\n",
    "        # with gzip.open(load_path, 'rb') as f:\n",
    "        dic = pickle.load(f)\n",
    "    return dic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
